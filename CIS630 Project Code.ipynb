{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b376e8-397f-4cd2-bba6-0566e91c60d3",
   "metadata": {},
   "source": [
    "Loading pakcages and data (images) into notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1a5b2a-52d8-47d9-a186-c8c5adf48c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packages\n",
    "import os  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "\n",
    "image_folder = \"/Users/shikhusanjel/Desktop/CNNTEST/Images\"\n",
    "train_lines_path = \"/Users/shikhusanjel/Desktop/CNNTEST/Sets/TrainLines.txt\"\n",
    "transcription_folder = \"/Users/shikhusanjel/Desktop/CNNTEST/Transcriptions\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce0dcff-99d2-4247-a200-b37729e44c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Applications/anaconda3/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Applications/anaconda3/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "import cv2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75423006-d5b2-4049-9688-4636aeede0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in dataset: ['.DS_Store', 'Images', 'Untitled.ipynb', 'Transcriptions', 'Sets', '.ipynb_checkpoints']\n"
     ]
    }
   ],
   "source": [
    "# data path\n",
    "data_folder = \"/Users/shikhusanjel/Desktop/CNNTEST\"\n",
    "\n",
    "# file names listed\n",
    "print(\"Files in dataset:\", os.listdir(data_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5705e42a-b281-49b7-b73a-7a3ca5ed4b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded TrainLines.txt\n",
      "First 5 filenames: ['train2011-150_000001', 'train2011-150_000002', 'train2011-150_000003', 'train2011-150_000004', 'train2011-150_000005']\n"
     ]
    }
   ],
   "source": [
    "train_lines_path = \"/Users/shikhusanjel/Desktop/CNNTEST/Sets/TrainLines.txt\" \n",
    "\n",
    "# read and store file names\n",
    "with open(\"/Users/shikhusanjel/Desktop/CNNTEST/Sets/TrainLines.txt\", \"r\") as file:\n",
    "    train_filenames = file.read().splitlines()  \n",
    "\n",
    "print(\"Successfully loaded TrainLines.txt\")\n",
    "print(\"First 5 filenames:\", train_filenames[:5])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e68424c1-a663-4b69-9f07-31221d211a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image path creation done. Missing files: 0\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"/Users/shikhusanjel/Desktop/CNNTEST/Images\"  \n",
    "\n",
    "train_images = [os.path.join(image_folder, f\"{name}.jpg\") for name in train_filenames]\n",
    "missing_files = [img for img in train_images if not os.path.exists(img)]\n",
    "\n",
    "print(f\"Image path creation done. Missing files: {len(missing_files)}\")\n",
    "if len(missing_files) > 0:\n",
    "    print(\"⚠ Some image files are missing. Check file extensions (JPG/PNG) or folder location.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "466a3d8d-e557-4a54-9d7e-20ca654963ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines_path = \"/Users/shikhusanjel/Desktop/CNNTTEST/Sets/TrainLines.txt\"  # Update if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7d24518-fe8a-4938-9c95-683a1ed04167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loading and displaying the first image\n",
    "img_path = train_images[0]  \n",
    "img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) \n",
    "\n",
    "if img is None:\n",
    "    print(\"⚠ Image loading failed. Check file path and extension.\")\n",
    "else:\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(\"Sample Image\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddfbc187-0e38-4b95-a059-60fca7903d92",
   "metadata": {},
   "source": [
    "Preprocess Images for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f999f8b-dd23-4463-b1b0-372335b95397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete! Processed 10188 images\n",
      "Image shape: (32, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "#Resize images to (128x32) pixels for uniform input size\n",
    "#Normalize pixel values between 0 and 1 for better training\n",
    "#Convert images into NumPy arrays for efficient processing.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# define image size \n",
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 128\n",
    "\n",
    "# the function to preprocess an image\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load grayscale\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))  # Resize to uniform size\n",
    "    img = img / 255.0  # Normalize pixel values between 0-1\n",
    "    img = np.expand_dims(img, axis=-1)  # Add channel dimension for CNN\n",
    "    return img\n",
    "\n",
    "# applying preprocessing to all images\n",
    "train_images_processed = np.array([preprocess_image(img_path) for img_path in train_images])\n",
    "\n",
    "print(f\"Preprocessing complete! Processed {len(train_images_processed)} images\")\n",
    "print(f\"Image shape: {train_images_processed[0].shape}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb26956-8b9e-401d-ae34-57666141c3b6",
   "metadata": {},
   "source": [
    "Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d24f88a-3fc8-47f4-bb5f-53e816e4be9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images found: 10188\n",
      "Missing images: 0\n"
     ]
    }
   ],
   "source": [
    "# path to TrainLines.txt\n",
    "train_lines_path = \"/Users/shikhusanjel/Desktop/CNNTEST/Sets/TrainLines.txt\"\n",
    "\n",
    "# path to Images folder\n",
    "image_folder = \"/Users/shikhusanjel/Desktop/CNNTEST/Images\"\n",
    "\n",
    "# read TrainLines.txt and extract filenames\n",
    "with open(train_lines_path, \"r\") as file:\n",
    "    train_filenames = [line.strip() for line in file.readlines()]  \n",
    "\n",
    "# convert filenames to full image paths\n",
    "train_images = [os.path.join(image_folder, f\"{name}.jpg\") for name in train_filenames]\n",
    "\n",
    "# check if files exist\n",
    "missing_files = [img for img in train_images if not os.path.exists(img)]\n",
    "\n",
    "# output \n",
    "print(f\"Total images found: {len(train_images) - len(missing_files)}\")\n",
    "print(f\"Missing images: {len(missing_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99c2e2f8-cf1b-4247-99e7-0e4869bfc02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labels loaded: 10188\n",
      "Missing labels: 0\n",
      "\n",
      "Sample image-label pairs:\n",
      "/Users/shikhusanjel/Desktop/CNNTEST/Images/train2011-150_000001.jpg -> J'ai perdu mon emploi depuis 3 mois et je me\n",
      "/Users/shikhusanjel/Desktop/CNNTEST/Images/train2011-150_000002.jpg -> retrouve en grande difficulté financière.\n",
      "/Users/shikhusanjel/Desktop/CNNTEST/Images/train2011-150_000003.jpg -> Je vous demande donc de m'accorder des\n",
      "/Users/shikhusanjel/Desktop/CNNTEST/Images/train2011-150_000004.jpg -> facilités de paiement et si cela était possible\n",
      "/Users/shikhusanjel/Desktop/CNNTEST/Images/train2011-150_000005.jpg -> une réduction sur mon tarif d'électricité.\n"
     ]
    }
   ],
   "source": [
    "# path to folder \n",
    "transcriptions_folder = \"/Users/shikhusanjel/Desktop/CNNTEST/Transcriptions\"\n",
    "\n",
    "# dictionary to store labels (image name to label content)\n",
    "train_labels = {}\n",
    "\n",
    "# read transcriptions for each image in train_images\n",
    "for image_path in train_images:\n",
    "    image_name = os.path.basename(image_path).replace(\".jpg\", \".txt\")  \n",
    "    transcription_path = os.path.join(transcriptions_folder, image_name)\n",
    "    \n",
    "    # Check if transcription file exists\n",
    "    if os.path.exists(transcription_path):\n",
    "        with open(transcription_path, \"r\") as file:\n",
    "            train_labels[image_path] = file.read().strip()  \n",
    "    else:\n",
    "        train_labels[image_path] = None  \n",
    "\n",
    "# results\n",
    "print(f\"Total labels loaded: {sum(1 for v in train_labels.values() if v is not None)}\")\n",
    "print(f\"Missing labels: {sum(1 for v in train_labels.values() if v is None)}\")\n",
    "\n",
    "# print first 5 images with labels\n",
    "print(\"\\nSample image-label pairs:\")\n",
    "for img, lbl in list(train_labels.items())[:5]:\n",
    "    print(f\"{img} -> {lbl}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "383d3567-b14b-490a-9b81-5a13cf9ecb5f",
   "metadata": {},
   "source": [
    "Load Images & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d72ff73d-25aa-43ed-a4ab-345d331b43ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total labels loaded: 10188\n",
      " Missing labels: 0\n",
      "\n",
      " Sample image-label pairs:\n",
      "/Users/shikhusanjel/Desktop/CNNTEST/Images/train2011-150_000001.jpg -> J'ai perdu mon emploi depuis 3 mois et je me\n",
      "/Users/shikhusanjel/Desktop/CNNTEST/Images/train2011-150_000002.jpg -> retrouve en grande difficulté financière.\n",
      "/Users/shikhusanjel/Desktop/CNNTEST/Images/train2011-150_000003.jpg -> Je vous demande donc de m'accorder des\n",
      "/Users/shikhusanjel/Desktop/CNNTEST/Images/train2011-150_000004.jpg -> facilités de paiement et si cela était possible\n",
      "/Users/shikhusanjel/Desktop/CNNTEST/Images/train2011-150_000005.jpg -> une réduction sur mon tarif d'électricité.\n"
     ]
    }
   ],
   "source": [
    "#Load and Match Transcriptions\n",
    "\n",
    "# read transcriptions for each image in train_images\n",
    "for image_path in train_images:\n",
    "    image_name = os.path.basename(image_path).replace(\".jpg\", \".txt\")  \n",
    "    transcription_path = os.path.join(transcriptions_folder, image_name)\n",
    "    \n",
    "    # check if transcription file exists\n",
    "    if os.path.exists(transcription_path):\n",
    "        with open(transcription_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            train_labels[image_path] = file.read().strip()  \n",
    "    else:\n",
    "        train_labels[image_path] = None  \n",
    "\n",
    "# results\n",
    "total_labels = sum(1 for v in train_labels.values() if v is not None)\n",
    "missing_labels = sum(1 for v in train_labels.values() if v is None)\n",
    "\n",
    "print(f\" Total labels loaded: {total_labels}\")\n",
    "print(f\" Missing labels: {missing_labels}\")\n",
    "\n",
    "# Print first 5 images with labels\n",
    "print(\"\\n Sample image-label pairs:\")\n",
    "for img, lbl in list(train_labels.items())[:5]:\n",
    "    print(f\"{img} -> {lbl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1439d1f-4728-4931-87d7-d1ed425232a7",
   "metadata": {},
   "source": [
    "Tokenization and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebd7641b-4214-49f4-a663-ee5d547c836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03607818-276e-4c26-b974-9aa5f73297cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37e46459-b6e6-40d3-bba7-0a4f0f6ac21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text tokenization complete! Processed 10188 labels\n",
      "Example tokenized label: [19, 21, 7, 6, 1, 15, 2, 4, 11, 10, 1, 12, 8, 5, 1, 2, 12, 15, 13, 8, 6, 1, 11, 2, 15, 10, 6, 3, 1, 39, 1, 12, 8, 6, 3, 1, 2, 9, 1, 19, 2, 1, 12, 2]\n",
      "Example padded label: [19 21  7  6  1 15  2  4 11 10  1 12  8  5  1  2 12 15 13  8  6  1 11  2\n",
      " 15 10  6  3  1 39  1 12  8  6  3  1  2  9  1 19  2  1 12  2  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# extract transcriptions \n",
    "texts = [label for label in train_labels.values() if label is not None]\n",
    "\n",
    "# initialize tokenizer and fit on text data\n",
    "tokenizer = Tokenizer(char_level=True, oov_token=None)  # Character-level tokenization\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# convert text labels to sequences of numbers\n",
    "train_sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# pad sequences to ensure uniform length\n",
    "max_length = max(len(seq) for seq in train_sequences)  # Find longest label\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=\"post\")\n",
    "\n",
    "print(f\"Text tokenization complete! Processed {len(train_padded)} labels\")\n",
    "print(f\"Example tokenized label: {train_sequences[0]}\")\n",
    "print(f\"Example padded label: {train_padded[0]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3a07027-5273-4d8c-a369-5247f8fb13e9",
   "metadata": {},
   "source": [
    "Splitting Data into Train/Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c9c4451d-5aec-44d9-a229-aefbf76850a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated image count: 5216\n"
     ]
    }
   ],
   "source": [
    "# Keep only images that have corresponding labels\n",
    "filtered_train_images = [img for img in train_images if img in train_labels]\n",
    "\n",
    "print(f\"Updated image count: {len(filtered_train_images)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a540d668-51f8-41dc-9994-f517090684b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 4172, Test images: 1044\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure image paths and labels match in length\n",
    "train_img_paths, test_img_paths, train_texts, test_texts = train_test_split(\n",
    "    filtered_train_images,  # Filtered images only\n",
    "    [train_labels[img] for img in filtered_train_images],  \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Convert back into dictionaries\n",
    "train_labels = dict(zip(train_img_paths, train_texts))\n",
    "test_labels = dict(zip(test_img_paths, test_texts))\n",
    "\n",
    "print(f\"Training images: {len(train_labels)}, Test images: {len(test_labels)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b5dd2-b359-4dbf-882c-1bc34b76bca8",
   "metadata": {},
   "source": [
    "Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2e1a1bd7-061a-42b1-8da5-bf5df96682e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ image_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">656,384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,247</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ image_input (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m656,384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m394,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m71\u001b[0m)         │        \u001b[38;5;34m18,247\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,161,543</span> (4.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,161,543\u001b[0m (4.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,161,543</span> (4.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,161,543\u001b[0m (4.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#starting  CNN + BiLSTM + CTC model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Bidirectional, LSTM, Input, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# input shape\n",
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 128\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1  # Number of unique characters + 1 for padding\n",
    "\n",
    "# input layer\n",
    "input_img = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1), name=\"image_input\")\n",
    "\n",
    "# CNN feature extractor\n",
    "x = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(input_img)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "# reshape for LSTM input\n",
    "x = Reshape(target_shape=((IMG_WIDTH // 8), (IMG_HEIGHT // 8) * 128))(x)\n",
    "\n",
    "# BiLSTM for sequence modeling\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "\n",
    "# output layer with softmax activation for character prediction\n",
    "output = Dense(VOCAB_SIZE, activation=\"softmax\", name=\"output\")(x)\n",
    "\n",
    "# defined model\n",
    "model = Model(inputs=input_img, outputs=output)\n",
    "\n",
    "# model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b18504d-50c9-456d-9c09-a85eeb86426d",
   "metadata": {},
   "source": [
    " Preprocess the Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d9dfba50-7b83-49a3-850e-e09c12cf0d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete! Processed 1044 test images.\n",
      "Example test image shape: (32, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the test images\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  \n",
    "    img = cv2.resize(img, (128, 32))  \n",
    "    img = img / 255.0  \n",
    "    img = np.expand_dims(img, axis=-1)  \n",
    "    return img\n",
    "\n",
    "# Apply preprocessing to test images\n",
    "test_images_processed = np.array([preprocess_image(img_path) for img_path in test_img_paths])\n",
    "\n",
    "print(f\"Preprocessing complete! Processed {len(test_images_processed)} test images.\")\n",
    "print(f\"Example test image shape: {test_images_processed[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "98b6a984-5207-4d3a-b0d5-a01c702849e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Train Label Shape: (10188, 16)\n",
      "New Test Label Shape: (1044, 16)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH = 16  # Match the model's output length\n",
    "\n",
    "# Re-run tokenization & padding with updated length\n",
    "train_sequences_padded = pad_sequences(train_sequences, maxlen=MAX_SEQ_LENGTH, padding=\"post\")\n",
    "test_sequences_padded = pad_sequences(test_sequences, maxlen=MAX_SEQ_LENGTH, padding=\"post\")\n",
    "\n",
    "print(f\"New Train Label Shape: {train_sequences_padded.shape}\")  # Should now match (None, 16)\n",
    "print(f\"New Test Label Shape: {test_sequences_padded.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "248fc392-c616-431b-9f99-edca68f12edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images Shape: (10188, 32, 128, 1)\n",
      "Train Labels Shape: (10188, 16)\n",
      "Test Images Shape: (1044, 32, 128, 1)\n",
      "Test Labels Shape: (1044, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Images Shape:\", np.array(train_images_processed).shape)\n",
    "print(\"Train Labels Shape:\", np.array(train_sequences_padded).shape)\n",
    "print(\"Test Images Shape:\", np.array(test_images_processed).shape)\n",
    "print(\"Test Labels Shape:\", np.array(test_sequences_padded).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3a20e1-9fc9-4a73-bc11-ad17a825108f",
   "metadata": {},
   "source": [
    "Start Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4c39f845-bfb4-4105-b1d7-d6e3fd2c419c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",          # You can change to another optimizer if needed\n",
    "    loss=\"sparse_categorical_crossentropy\",  # Use categorical loss for text classification\n",
    "    metrics=[\"accuracy\"]       # Track accuracy during training\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b20dd199-46aa-4f9f-bd36-24e8dccec08d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_images_processed, train_sequences_padded, \n\u001b[1;32m      7\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39mEPOCHS, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, \n\u001b[1;32m      8\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39m(test_images_processed, test_sequences_padded))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "# Train model\n",
    "history = model.fit(train_images_processed, train_sequences_padded, \n",
    "                    epochs=EPOCHS, batch_size=BATCH_SIZE, \n",
    "                    validation_data=(test_images_processed, test_sequences_padded))\n",
    "\n",
    "print(\"Training completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73fc538-6223-4235-af1e-f0989111a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after epochs run: \n",
    "\n",
    "#evaluate model\n",
    "test_loss, test_acc = model.evaluate(test_images_processed, test_sequences_padded)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}, Test Loss: {test_loss:.2f}\")\n",
    "\n",
    "#save model without retraining\n",
    "model.save(\"handwriting_model.h5\")\n",
    "print(\"Model saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
